{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9afdd2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c0303405144312badab4f2bb02b52d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  54%|#####4    | 1.24G/2.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "AsymmetricCroCo3DStereo(\n",
       "  (patch_embed): PatchEmbedDust3R(\n",
       "    (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (mask_generator): RandomMask()\n",
       "  (rope): RoPE2D()\n",
       "  (enc_blocks): ModuleList(\n",
       "    (0-23): 24 x Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        (rope): RoPE2D()\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (enc_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "  (decoder_embed): Linear(in_features=1024, out_features=768, bias=True)\n",
       "  (dec_blocks): ModuleList(\n",
       "    (0-11): 12 x DecoderBlock(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        (rope): RoPE2D()\n",
       "      )\n",
       "      (cross_attn): CrossAttention(\n",
       "        (projq): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (projk): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (projv): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        (rope): RoPE2D()\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm_y): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (dec_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  (dec_blocks2): ModuleList(\n",
       "    (0-11): 12 x DecoderBlock(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        (rope): RoPE2D()\n",
       "      )\n",
       "      (cross_attn): CrossAttention(\n",
       "        (projq): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (projk): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (projv): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        (rope): RoPE2D()\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm_y): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (downstream_head1): PixelwiseTaskWithDPT(\n",
       "    (dpt): DPTOutputAdapter_fix(\n",
       "      (scratch): Module(\n",
       "        (layer1_rn): Conv2d(96, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (layer2_rn): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (layer3_rn): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (layer4_rn): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (layer_rn): ModuleList(\n",
       "          (0): Conv2d(96, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (2): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (3): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (refinenet1): FeatureFusionBlock_custom(\n",
       "          (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (resConfUnit1): ResidualConvUnit_custom(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (resConfUnit2): ResidualConvUnit_custom(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (refinenet2): FeatureFusionBlock_custom(\n",
       "          (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (resConfUnit1): ResidualConvUnit_custom(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (resConfUnit2): ResidualConvUnit_custom(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (refinenet3): FeatureFusionBlock_custom(\n",
       "          (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (resConfUnit1): ResidualConvUnit_custom(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (resConfUnit2): ResidualConvUnit_custom(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (refinenet4): FeatureFusionBlock_custom(\n",
       "          (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (resConfUnit1): ResidualConvUnit_custom(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (resConfUnit2): ResidualConvUnit_custom(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (head): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Interpolate()\n",
       "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (act_postprocess): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(1024, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ConvTranspose2d(96, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ConvTranspose2d(192, 192, kernel_size=(2, 2), stride=(2, 2))\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): Conv2d(768, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (downstream_head2): PixelwiseTaskWithDPT(\n",
       "    (dpt): DPTOutputAdapter_fix(\n",
       "      (scratch): Module(\n",
       "        (layer1_rn): Conv2d(96, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (layer2_rn): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (layer3_rn): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (layer4_rn): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (layer_rn): ModuleList(\n",
       "          (0): Conv2d(96, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (2): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (3): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (refinenet1): FeatureFusionBlock_custom(\n",
       "          (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (resConfUnit1): ResidualConvUnit_custom(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (resConfUnit2): ResidualConvUnit_custom(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (refinenet2): FeatureFusionBlock_custom(\n",
       "          (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (resConfUnit1): ResidualConvUnit_custom(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (resConfUnit2): ResidualConvUnit_custom(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (refinenet3): FeatureFusionBlock_custom(\n",
       "          (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (resConfUnit1): ResidualConvUnit_custom(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (resConfUnit2): ResidualConvUnit_custom(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (refinenet4): FeatureFusionBlock_custom(\n",
       "          (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (resConfUnit1): ResidualConvUnit_custom(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (resConfUnit2): ResidualConvUnit_custom(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (head): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Interpolate()\n",
       "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (act_postprocess): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(1024, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ConvTranspose2d(96, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ConvTranspose2d(192, 192, kernel_size=(2, 2), stride=(2, 2))\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): Conv2d(768, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# huggingface_hub integration\n",
    "from dust3r.model import AsymmetricCroCo3DStereo\n",
    "import torch\n",
    "\n",
    "model = AsymmetricCroCo3DStereo.from_pretrained(\"nielsr/DUSt3R_ViTLarge_BaseDecoder_512_dpt\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f130ed7f",
   "metadata": {},
   "source": [
    "## Office frame 0-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7aa7568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Loading a list of 2 images\n",
      " - adding office_frames/frame0.jpg with resolution 1080x1920 --> 288x512\n",
      " - adding office_frames/frame1.jpg with resolution 1080x1920 --> 288x512\n",
      " (Found 2 images)\n",
      ">> Inference with model on 2 image pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:23<00:00, 11.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix has been written to img0.csv\n",
      "Matrix has been written to img1.csv\n",
      ">> Loading a list of 2 images\n",
      " - adding office_frames/frame1.jpg with resolution 1080x1920 --> 288x512\n",
      " - adding office_frames/frame2.jpg with resolution 1080x1920 --> 288x512\n",
      " (Found 2 images)\n",
      ">> Inference with model on 2 image pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:21<00:00, 10.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix has been written to img1.csv\n",
      "Matrix has been written to img2.csv\n",
      ">> Loading a list of 2 images\n",
      " - adding office_frames/frame2.jpg with resolution 1080x1920 --> 288x512\n",
      " - adding office_frames/frame3.jpg with resolution 1080x1920 --> 288x512\n",
      " (Found 2 images)\n",
      ">> Inference with model on 2 image pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:22<00:00, 11.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix has been written to img2.csv\n",
      "Matrix has been written to img3.csv\n",
      ">> Loading a list of 2 images\n",
      " - adding office_frames/frame3.jpg with resolution 1080x1920 --> 288x512\n",
      " - adding office_frames/frame4.jpg with resolution 1080x1920 --> 288x512\n",
      " (Found 2 images)\n",
      ">> Inference with model on 2 image pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:22<00:00, 11.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix has been written to img3.csv\n",
      "Matrix has been written to img4.csv\n",
      ">> Loading a list of 2 images\n",
      " - adding office_frames/frame4.jpg with resolution 1080x1920 --> 288x512\n",
      " - adding office_frames/frame5.jpg with resolution 1080x1920 --> 288x512\n",
      " (Found 2 images)\n",
      ">> Inference with model on 2 image pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:22<00:00, 11.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix has been written to img4.csv\n",
      "Matrix has been written to img5.csv\n"
     ]
    }
   ],
   "source": [
    "from dust3r.inference import inference\n",
    "from dust3r.model import AsymmetricCroCo3DStereo\n",
    "from dust3r.utils.image import load_images\n",
    "from dust3r.image_pairs import make_pairs\n",
    "from dust3r.cloud_opt import global_aligner, GlobalAlignerMode\n",
    "\n",
    "import csv\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    device = 'cpu'\n",
    "    batch_size = 1\n",
    "    schedule = 'cosine'\n",
    "    lr = 0.01\n",
    "    niter = 300\n",
    "\n",
    "    model_name = \"naver/DUSt3R_ViTLarge_BaseDecoder_512_dpt\"\n",
    "    model = AsymmetricCroCo3DStereo.from_pretrained(model_name).to(device)\n",
    "    \n",
    "    for i in range(0, 5):\n",
    "        images = load_images([\"office_frames/frame%d.jpg\" % i, \"office_frames/frame%d.jpg\" % (i+1)], size=512)\n",
    "\n",
    "        pairs = make_pairs(images, scene_graph='complete', prefilter=None, symmetrize=True)\n",
    "        output = inference(pairs, model, device, batch_size=batch_size)\n",
    "\n",
    "        # at this stage, you have the raw dust3r predictions\n",
    "        view1, pred1 = output['view1'], output['pred1']\n",
    "        view2, pred2 = output['view2'], output['pred2']\n",
    "\n",
    "        output = 'img%d.csv' % i\n",
    "        # Open the file in write mode\n",
    "        with open(output, mode='w', newline='') as file:\n",
    "\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['x', 'y', 'z', 'r', 'g', 'b'])\n",
    "\n",
    "            # Write each row of the matrix to the CSV file\n",
    "            for r, row in enumerate(pred1['pts3d'][0]):\n",
    "                for c, element in enumerate(row):\n",
    "                    data = element.tolist()\n",
    "\n",
    "                    data.append(view1['img'][0][0, r, c].tolist())\n",
    "                    data.append(view1['img'][0][1, r, c].tolist())\n",
    "                    data.append(view1['img'][0][2, r, c].tolist())\n",
    "\n",
    "                    writer.writerow(data)\n",
    "\n",
    "        print(f\"Matrix has been written to {output}\")\n",
    "\n",
    "        output = 'img%d.csv' % (i+1)\n",
    "\n",
    "        # Open the file in write mode\n",
    "        with open(output, mode='w', newline='') as file:\n",
    "\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['x', 'y', 'z', 'r', 'g', 'b'])\n",
    "\n",
    "            # Write each row of the matrix to the CSV file\n",
    "            for r, row in enumerate(pred2['pts3d_in_other_view'][0]):\n",
    "                for c, element in enumerate(row):\n",
    "                    data = element.tolist()\n",
    "\n",
    "                    data.append(view2['img'][0][0, r, c].tolist())\n",
    "                    data.append(view2['img'][0][1, r, c].tolist())\n",
    "                    data.append(view2['img'][0][2, r, c].tolist())\n",
    "\n",
    "                    writer.writerow(data)\n",
    "\n",
    "        print(f\"Matrix has been written to {output}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc0a42c",
   "metadata": {},
   "source": [
    "## Gate frames 0-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f3b15b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning, cannot find cuda-compiled version of RoPE2D, using a slow pytorch version instead\n",
      ">> Loading a list of 2 images\n",
      " - adding gate_frames/frame0.jpg with resolution 1080x1920 --> 288x512\n",
      " - adding gate_frames/frame1.jpg with resolution 1080x1920 --> 288x512\n",
      " (Found 2 images)\n",
      ">> Inference with model on 2 image pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:21<00:00, 10.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix has been written to gate_frames_csv/img0.csv\n",
      "Matrix has been written to gate_frames_csv/img1.csv\n",
      ">> Loading a list of 2 images\n",
      " - adding gate_frames/frame0.jpg with resolution 1080x1920 --> 288x512\n",
      " - adding gate_frames/frame2.jpg with resolution 1080x1920 --> 288x512\n",
      " (Found 2 images)\n",
      ">> Inference with model on 2 image pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:21<00:00, 10.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix has been written to gate_frames_csv/img2.csv\n",
      ">> Loading a list of 2 images\n",
      " - adding gate_frames/frame0.jpg with resolution 1080x1920 --> 288x512\n",
      " - adding gate_frames/frame3.jpg with resolution 1080x1920 --> 288x512\n",
      " (Found 2 images)\n",
      ">> Inference with model on 2 image pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:21<00:00, 10.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix has been written to gate_frames_csv/img3.csv\n",
      ">> Loading a list of 2 images\n",
      " - adding gate_frames/frame0.jpg with resolution 1080x1920 --> 288x512\n",
      " - adding gate_frames/frame4.jpg with resolution 1080x1920 --> 288x512\n",
      " (Found 2 images)\n",
      ">> Inference with model on 2 image pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:22<00:00, 11.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix has been written to gate_frames_csv/img4.csv\n",
      ">> Loading a list of 2 images\n",
      " - adding gate_frames/frame0.jpg with resolution 1080x1920 --> 288x512\n",
      " - adding gate_frames/frame5.jpg with resolution 1080x1920 --> 288x512\n",
      " (Found 2 images)\n",
      ">> Inference with model on 2 image pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:21<00:00, 10.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix has been written to gate_frames_csv/img5.csv\n",
      ">> Loading a list of 2 images\n",
      " - adding gate_frames/frame0.jpg with resolution 1080x1920 --> 288x512\n",
      " - adding gate_frames/frame6.jpg with resolution 1080x1920 --> 288x512\n",
      " (Found 2 images)\n",
      ">> Inference with model on 2 image pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:21<00:00, 10.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix has been written to gate_frames_csv/img6.csv\n"
     ]
    }
   ],
   "source": [
    "from dust3r.inference import inference\n",
    "from dust3r.model import AsymmetricCroCo3DStereo\n",
    "from dust3r.utils.image import load_images\n",
    "from dust3r.image_pairs import make_pairs\n",
    "from dust3r.cloud_opt import global_aligner, GlobalAlignerMode\n",
    "\n",
    "import csv\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    device = 'cpu'\n",
    "    batch_size = 1\n",
    "    schedule = 'cosine'\n",
    "    lr = 0.01\n",
    "    niter = 300\n",
    "\n",
    "    model_name = \"naver/DUSt3R_ViTLarge_BaseDecoder_512_dpt\"\n",
    "    model = AsymmetricCroCo3DStereo.from_pretrained(model_name).to(device)\n",
    "    \n",
    "    for i in range(1, 7):\n",
    "        images = load_images([\"gate_frames/frame0.jpg\", \"gate_frames/frame%d.jpg\" % i], size=512)\n",
    "\n",
    "        pairs = make_pairs(images, scene_graph='complete', prefilter=None, symmetrize=True)\n",
    "        output = inference(pairs, model, device, batch_size=batch_size)\n",
    "\n",
    "        view1, pred1 = output['view1'], output['pred1']\n",
    "        view2, pred2 = output['view2'], output['pred2']\n",
    "\n",
    "        # only in the first iteration, never overwrite\n",
    "        if i == 1:\n",
    "            output = 'gate_frames_csv/img0.csv'\n",
    "            with open(output, mode='w', newline='') as file:\n",
    "\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(['x', 'y', 'z', 'r', 'g', 'b'])\n",
    "\n",
    "                # Write each row of the matrix to the CSV file\n",
    "                for r, row in enumerate(pred1['pts3d'][0]):\n",
    "                    for c, element in enumerate(row):\n",
    "                        data = element.tolist()\n",
    "\n",
    "                        data.append(view1['img'][0][0, r, c].tolist())\n",
    "                        data.append(view1['img'][0][1, r, c].tolist())\n",
    "                        data.append(view1['img'][0][2, r, c].tolist())\n",
    "\n",
    "                        writer.writerow(data)\n",
    "\n",
    "            print(f\"Matrix has been written to {output}\")\n",
    "\n",
    "        output = 'gate_frames_csv/img%d.csv' % (i)\n",
    "\n",
    "        # Open the file in write mode\n",
    "        with open(output, mode='w', newline='') as file:\n",
    "\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['x', 'y', 'z', 'r', 'g', 'b'])\n",
    "\n",
    "            # Write each row of the matrix to the CSV file\n",
    "            for r, row in enumerate(pred2['pts3d_in_other_view'][0]):\n",
    "                for c, element in enumerate(row):\n",
    "                    data = element.tolist()\n",
    "\n",
    "                    data.append(view2['img'][0][0, r, c].tolist())\n",
    "                    data.append(view2['img'][0][1, r, c].tolist())\n",
    "                    data.append(view2['img'][0][2, r, c].tolist())\n",
    "\n",
    "                    writer.writerow(data)\n",
    "\n",
    "        print(f\"Matrix has been written to {output}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba341db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to load a point cloud from a CSV file\n",
    "def foo(i):\n",
    "    csv_file = f'gate_frames_csv/img{i}.csv'  # Use f-string for dynamic file name\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Assuming your CSV file has columns named 'x', 'y', 'z', 'r', 'g', 'b'\n",
    "    points = df[['x', 'y', 'z']].values\n",
    "    colors = df[['r', 'g', 'b']].values\n",
    "\n",
    "    # Create and return a PointCloud object\n",
    "    point_cloud = o3d.geometry.PointCloud()\n",
    "    point_cloud.points = o3d.utility.Vector3dVector(points)\n",
    "    point_cloud.colors = o3d.utility.Vector3dVector(colors)\n",
    "    \n",
    "    return point_cloud\n",
    "\n",
    "point_clouds = [foo(i) for i in range(7)]\n",
    "o3d.visualization.draw_geometries(point_clouds)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dust3r)",
   "language": "python",
   "name": "dust3r"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
